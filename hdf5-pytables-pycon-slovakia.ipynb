{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with HDF5 and PyTables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*11/03/2018 - Giacomo Debidda @PyCon Slovakia*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tables as tb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2, suppress=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Repos/hdf5-pycon-slovakia/data\n"
     ]
    }
   ],
   "source": [
    "data_dir = os.path.join(os.getcwd(), 'data')\n",
    "print(data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5: a filesystem in a file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 is a data model, library, and file format for storing and managing big and complex data.\n",
    "\n",
    "An HDF5 file can be thought of as a container (or group) that holds a variety of heterogeneous data objects (or datasets). The datasets can be almost anything: images, tables, graphs, or even documents, such as PDF or Excel.\n",
    "\n",
    "- Datasets (i.e. files in a filesystem)\n",
    "- Groups (i.e. directories in a filesystem)\n",
    "- Attributes (i.e. metadata of file/directory)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![HDF5 structure](img/hdf5_structure.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Working with groups and group members is similar to working with directories and files in UNIX.\n",
    "\n",
    "**/** root group (every HDF5 file has a root group)\n",
    "\n",
    "**/foo** member of the root group called foo\n",
    "\n",
    "**/foo/bar** member of the group foo called bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 in the Python data stack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![h5py - PyTables refactor](img/h5py-pytables-refactor.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![PyTables logo](img/pytables-logo.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Does not want to be a complete wrapper for the entire HDF5 C API\n",
    "- High level abstraction over HDF5 (it's more \"battery included\" than h5py)\n",
    "- Does not depend on h5py (at the moment)\n",
    "- Natural naming\n",
    "- Fast searches (indexing, out-of-core querying)\n",
    "- Built-in compression\n",
    "- Undo mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Groups, Attributes, ~~Datasets~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a brief overview of the PyTables API.\n",
    "\n",
    "> Let's forget HDF5 Datasets for a moment...\n",
    "\n",
    "- how to create groups, attributes and arrays\n",
    "- how to access nodes in a HDF5 file\n",
    "- how to access data in a node"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural naming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PyTables nodes (i.e. any element in the hierarchy of the HDF5 file) can be accessed with the dot notation if they follow a *natural naming* schema (like in pandas)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    f.create_group(where='/', name='my_group')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jack/.virtualenvs/hdf5-pycon-slovakia/lib/python3.6/site-packages/tables/path.py:112: NaturalNameWarning: object name is not a valid Python identifier: 'my group'; it does not match the pattern ``^[a-zA-Z_][a-zA-Z0-9_]*$``; you will not be able to use natural naming to access this object; using ``getattr()`` will still work, though\n",
      "  NaturalNameWarning)\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    f.create_group(where='/', name='my group')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When a node which does not follow the natural naming schema you can still use `get_node` to access it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/my group (Group) ''\n",
      "/my group (Group) ''\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='r') as f:\n",
    "    my_group = f.get_node(where='/my group')\n",
    "    print(my_group)\n",
    "    my_group = f.get_node(where='/', name='my group')\n",
    "    print(my_group)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's create some data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  0,  11,  22,  33,  44,  55,  66,  77,  88, 100], dtype=int8)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr1d = np.linspace(start=0, stop=100, num=10, dtype=np.int8)\n",
    "arr1d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  2.],\n",
       "       [ 3.,  4.,  5.],\n",
       "       [ 6.,  7.,  8.],\n",
       "       [ 9., 10., 11.],\n",
       "       [12., 13., 14.],\n",
       "       [15., 16., 17.],\n",
       "       [18., 19., 20.],\n",
       "       [21., 22., 23.],\n",
       "       [24., 25., 26.],\n",
       "       [27., 28., 29.]], dtype=float32)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr2d = np.arange(30, dtype=np.float32).reshape(10, 3)\n",
    "arr2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.64, 0.14, 0.49, 0.07, 0.4 ],\n",
       "        [0.44, 0.52, 0.39, 0.05, 0.14],\n",
       "        [0.11, 0.11, 0.95, 0.65, 0.89]],\n",
       "\n",
       "       [[0.3 , 0.36, 0.5 , 0.63, 0.19],\n",
       "        [0.11, 0.99, 0.27, 0.63, 0.37],\n",
       "        [0.91, 0.97, 0.78, 0.13, 0.74]],\n",
       "\n",
       "       [[0.03, 0.92, 0.5 , 0.21, 0.99],\n",
       "        [0.91, 0.62, 0.41, 0.95, 0.97],\n",
       "        [0.12, 0.76, 0.48, 0.53, 0.96]],\n",
       "\n",
       "       [[0.04, 0.08, 0.06, 0.97, 0.81],\n",
       "        [0.25, 0.03, 0.51, 0.67, 0.94],\n",
       "        [0.96, 0.47, 0.92, 0.92, 0.19]],\n",
       "\n",
       "       [[0.56, 0.22, 0.79, 0.64, 0.48],\n",
       "        [0.39, 0.19, 0.34, 0.32, 0.31],\n",
       "        [0.67, 0.26, 0.56, 0.43, 0.44]],\n",
       "\n",
       "       [[0.5 , 0.17, 0.31, 0.78, 0.91],\n",
       "        [0.22, 0.65, 0.05, 0.11, 0.47],\n",
       "        [0.09, 0.83, 0.27, 0.45, 0.11]],\n",
       "\n",
       "       [[0.62, 0.36, 0.2 , 0.2 , 0.93],\n",
       "        [0.96, 0.89, 0.5 , 0.96, 0.66],\n",
       "        [0.75, 0.26, 0.15, 0.79, 0.89]],\n",
       "\n",
       "       [[0.48, 0.67, 0.12, 0.02, 0.58],\n",
       "        [0.09, 0.34, 0.84, 0.75, 0.98],\n",
       "        [0.98, 0.37, 0.29, 0.52, 0.5 ]],\n",
       "\n",
       "       [[0.58, 0.86, 1.  , 0.25, 0.77],\n",
       "        [0.23, 0.42, 0.25, 0.24, 0.86],\n",
       "        [0.13, 0.65, 0.2 , 0.42, 0.95]],\n",
       "\n",
       "       [[0.5 , 0.41, 0.36, 0.37, 0.42],\n",
       "        [0.46, 0.3 , 0.84, 0.78, 0.76],\n",
       "        [0.29, 0.86, 0.69, 0.81, 0.87]]], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "arr3d = np.random.random((10, 3, 5)).astype('float32')\n",
    "arr3d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create groups, attributes, arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    f.create_array(where='/', \n",
    "                   name='array_1d',\n",
    "                   title='A one-dimensional Array',\n",
    "                   obj=arr1d)\n",
    "    f.set_node_attr(where='/array_1d', attrname='SomeAttribute', attrvalue='SomeValue')\n",
    "    \n",
    "    f.create_group(where='/', name='multidimensional_data', title='Multi dimensional data')\n",
    "    f.set_node_attr(where='/multidimensional_data', attrname='SomeOtherAttribute', attrvalue=123)\n",
    "    \n",
    "    f.create_array(where='/multidimensional_data', \n",
    "                   name='array_2d',\n",
    "                   title='A two-dimensional Array',\n",
    "                   obj=arr2d)\n",
    "    \n",
    "    f.create_array(where=f.root.multidimensional_data, \n",
    "                   name='array_3d',\n",
    "                   title='A three-dimensional Array',\n",
    "                   obj=arr3d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traverse a HDF5 file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/array_1d (Array(10,)) 'A one-dimensional Array'\n",
      "/multidimensional_data (Group) 'Multi dimensional data'\n",
      "/multidimensional_data/array_2d (Array(10, 3)) 'A two-dimensional Array'\n",
      "/multidimensional_data/array_3d (Array(10, 3, 5)) 'A three-dimensional Array'\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file('data/my_pytables_file.h5', 'r') as f:\n",
    "    for node in f:\n",
    "        print(node)\n",
    "        \n",
    "#     for node in f.walk_groups():\n",
    "#         print(node)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select a hyperslab of data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hyperslabs are portions of datasets. A hyperslab selection can be a logically contiguous collection of points in a dataspace, or it can be regular pattern of points or blocks in a dataspace."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "array([[0.91, 0.62, 0.41, 0.95, 0.97],\n",
      "       [0.25, 0.03, 0.51, 0.67, 0.94],\n",
      "       [0.39, 0.19, 0.34, 0.32, 0.31],\n",
      "       [0.22, 0.65, 0.05, 0.11, 0.47],\n",
      "       [0.96, 0.89, 0.5 , 0.96, 0.66]], dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='r') as f:\n",
    "    print(repr(f.root.multidimensional_data.array_3d[2:7, 1, :]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 CLI utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Here](https://support.hdfgroup.org/products/hdf5_tools/#h5dist) you can find the command line tools developed by the HDF Group. You don't need h5py or PyTables to use them.\n",
    "\n",
    "If you are on Ubuntu, you can install them with `sudo apt install hdf5-tools`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/                        Group\r\n",
      "/array_1d                Dataset {10}\r\n",
      "/multidimensional_data   Group\r\n",
      "/multidimensional_data/array_2d Dataset {10, 3}\r\n",
      "/multidimensional_data/array_3d Dataset {10, 3, 5}\r\n"
     ]
    }
   ],
   "source": [
    "# -r stands for 'recursive'\n",
    "!h5ls -r 'data/my_pytables_file.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HDF5 \"data/my_pytables_file.h5\" {\r\n",
      "GROUP \"/\" {\r\n",
      "   ATTRIBUTE \"CLASS\" {\r\n",
      "      DATATYPE  H5T_STRING {\r\n",
      "         STRSIZE 5;\r\n",
      "         STRPAD H5T_STR_NULLTERM;\r\n",
      "         CSET H5T_CSET_UTF8;\r\n",
      "         CTYPE H5T_C_S1;\r\n",
      "      }\r\n",
      "      DATASPACE  SCALAR\r\n",
      "      DATA {\r\n",
      "      (0): \"GROUP\"\r\n",
      "      }\r\n",
      "   }\r\n",
      "   ATTRIBUTE \"PYTABLES_FORMAT_VERSION\" {\r\n",
      "      DATATYPE  H5T_STRING {\r\n",
      "         STRSIZE 3;\r\n",
      "         STRPAD H5T_STR_NULLTERM;\r\n",
      "         CSET H5T_CSET_UTF8;\r\n",
      "         CTYPE H5T_C_S1;\r\n",
      "      }\r\n",
      "      DATASPACE  SCALAR\r\n",
      "      DATA {\r\n",
      "      (0): \"2.1\"\r\n",
      "      }\r\n",
      "   }\r\n",
      "   ATTRIBUTE \"TITLE\" {\r\n",
      "      DATATYPE  H5T_STRING {\r\n",
      "         STRSIZE 1;\r\n",
      "         STRPAD H5T_STR_NULLTERM;\r\n",
      "         CSET H5T_CSET_UTF8;\r\n",
      "         CTYPE H5T_C_S1;\r\n",
      "      }\r\n",
      "      DATASPACE  NULL\r\n",
      "      DATA {\r\n",
      "      }\r\n",
      "   }\r\n",
      "   ATTRIBUTE \"VERSION\" {\r\n",
      "      DATATYPE  H5T_STRING {\r\n",
      "         STRSIZE 3;\r\n",
      "         STRPAD H5T_STR_NULLTERM;\r\n",
      "         CSET H5T_CSET_UTF8;\r\n",
      "         CTYPE H5T_C_S1;\r\n",
      "      }\r\n",
      "      DATASPACE  SCALAR\r\n",
      "      DATA {\r\n",
      "      (0): \"1.0\"\r\n",
      "      }\r\n",
      "   }\r\n",
      "   DATASET \"array_1d\" {\r\n",
      "      DATATYPE  H5T_STD_I8LE\r\n",
      "      DATASPACE  SIMPLE { ( 10 ) / ( 10 ) }\r\n",
      "      DATA {\r\n",
      "      (0): 0, 11, 22, 33, 44, 55, 66, 77, 88, 100\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"CLASS\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 5;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"ARRAY\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"FLAVOR\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 5;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"numpy\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"SomeAttribute\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 9;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"SomeValue\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"TITLE\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 23;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"A one-dimensional Array\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"VERSION\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 3;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"2.4\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "   }\r\n",
      "   GROUP \"multidimensional_data\" {\r\n",
      "      ATTRIBUTE \"CLASS\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 5;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"GROUP\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"SomeOtherAttribute\" {\r\n",
      "         DATATYPE  H5T_STD_I64LE\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): 123\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"TITLE\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 22;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"Multi dimensional data\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      ATTRIBUTE \"VERSION\" {\r\n",
      "         DATATYPE  H5T_STRING {\r\n",
      "            STRSIZE 3;\r\n",
      "            STRPAD H5T_STR_NULLTERM;\r\n",
      "            CSET H5T_CSET_UTF8;\r\n",
      "            CTYPE H5T_C_S1;\r\n",
      "         }\r\n",
      "         DATASPACE  SCALAR\r\n",
      "         DATA {\r\n",
      "         (0): \"1.0\"\r\n",
      "         }\r\n",
      "      }\r\n",
      "      DATASET \"array_2d\" {\r\n",
      "         DATATYPE  H5T_IEEE_F32LE\r\n",
      "         DATASPACE  SIMPLE { ( 10, 3 ) / ( 10, 3 ) }\r\n",
      "         DATA {\r\n",
      "         (0,0): 0, 1, 2,\r\n",
      "         (1,0): 3, 4, 5,\r\n",
      "         (2,0): 6, 7, 8,\r\n",
      "         (3,0): 9, 10, 11,\r\n",
      "         (4,0): 12, 13, 14,\r\n",
      "         (5,0): 15, 16, 17,\r\n",
      "         (6,0): 18, 19, 20,\r\n",
      "         (7,0): 21, 22, 23,\r\n",
      "         (8,0): 24, 25, 26,\r\n",
      "         (9,0): 27, 28, 29\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"CLASS\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 5;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"ARRAY\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"FLAVOR\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 5;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"numpy\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"TITLE\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 23;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"A two-dimensional Array\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"VERSION\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 3;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"2.4\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "      DATASET \"array_3d\" {\r\n",
      "         DATATYPE  H5T_IEEE_F32LE\r\n",
      "         DATASPACE  SIMPLE { ( 10, 3, 5 ) / ( 10, 3, 5 ) }\r\n",
      "         DATA {\r\n",
      "         (0,0,0): 0.638543, 0.138044, 0.492169, 0.0669096, 0.396459,\r\n",
      "         (0,1,0): 0.439909, 0.523163, 0.394074, 0.0488327, 0.139395,\r\n",
      "         (0,2,0): 0.114148, 0.112495, 0.953156, 0.651184, 0.889477,\r\n",
      "         (1,0,0): 0.29501, 0.364587, 0.496471, 0.629858, 0.190253,\r\n",
      "         (1,1,0): 0.109786, 0.985613, 0.274062, 0.633961, 0.368236,\r\n",
      "         (1,2,0): 0.911261, 0.971081, 0.782658, 0.129538, 0.74175,\r\n",
      "         (2,0,0): 0.0337604, 0.916682, 0.499824, 0.209329, 0.992865,\r\n",
      "         (2,1,0): 0.912155, 0.615522, 0.411414, 0.946639, 0.969252,\r\n",
      "         (2,2,0): 0.116663, 0.756148, 0.47819, 0.526703, 0.964995,\r\n",
      "         (3,0,0): 0.036537, 0.0779596, 0.0604591, 0.969671, 0.812763,\r\n",
      "         (3,1,0): 0.25376, 0.0293835, 0.508031, 0.667168, 0.941031,\r\n",
      "         (3,2,0): 0.955361, 0.469132, 0.922838, 0.923194, 0.192717,\r\n",
      "         (4,0,0): 0.561106, 0.223387, 0.792752, 0.638261, 0.481206,\r\n",
      "         (4,1,0): 0.385364, 0.194971, 0.344144, 0.316965, 0.308796,\r\n",
      "         (4,2,0): 0.674432, 0.263562, 0.556529, 0.428061, 0.443687,\r\n",
      "         (5,0,0): 0.499123, 0.171087, 0.309998, 0.776567, 0.912039,\r\n",
      "         (5,1,0): 0.221882, 0.650348, 0.0458514, 0.109437, 0.471341,\r\n",
      "         (5,2,0): 0.0867943, 0.828834, 0.2664, 0.454865, 0.108615,\r\n",
      "         (6,0,0): 0.617108, 0.363011, 0.203361, 0.201003, 0.933446,\r\n",
      "         (6,1,0): 0.963173, 0.885955, 0.503048, 0.956128, 0.656243,\r\n",
      "         (6,2,0): 0.751454, 0.256614, 0.153116, 0.790914, 0.887405,\r\n",
      "         (7,0,0): 0.484461, 0.67419, 0.121179, 0.0240311, 0.581449,\r\n",
      "         (7,1,0): 0.0866204, 0.339431, 0.843012, 0.753864, 0.981273,\r\n",
      "         (7,2,0): 0.975555, 0.373091, 0.292818, 0.516144, 0.497795,\r\n",
      "         (8,0,0): 0.583912, 0.85917, 0.998712, 0.25107, 0.767486,\r\n",
      "         (8,1,0): 0.22685, 0.423202, 0.248821, 0.235184, 0.858473,\r\n",
      "         (8,2,0): 0.134708, 0.649324, 0.19909, 0.420142, 0.94982,\r\n",
      "         (9,0,0): 0.496562, 0.414045, 0.3552, 0.369509, 0.420723,\r\n",
      "         (9,1,0): 0.459889, 0.299808, 0.836122, 0.781222, 0.755663,\r\n",
      "         (9,2,0): 0.285079, 0.863806, 0.687345, 0.812065, 0.866128\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"CLASS\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 5;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"ARRAY\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"FLAVOR\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 5;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"numpy\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"TITLE\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 25;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"A three-dimensional Array\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "         ATTRIBUTE \"VERSION\" {\r\n",
      "            DATATYPE  H5T_STRING {\r\n",
      "               STRSIZE 3;\r\n",
      "               STRPAD H5T_STR_NULLTERM;\r\n",
      "               CSET H5T_CSET_UTF8;\r\n",
      "               CTYPE H5T_C_S1;\r\n",
      "            }\r\n",
      "            DATASPACE  SCALAR\r\n",
      "            DATA {\r\n",
      "            (0): \"2.4\"\r\n",
      "            }\r\n",
      "         }\r\n",
      "      }\r\n",
      "   }\r\n",
      "}\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!h5dump 'data/my_pytables_file.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTables CLI utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some very useful tools are shipped with PyTables. These are just python scripts that can be used from the command line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\r\n",
      "  /._v_attrs (AttributeSet), 4 attributes:\r\n",
      "   [CLASS := 'GROUP',\r\n",
      "    PYTABLES_FORMAT_VERSION := '2.1',\r\n",
      "    TITLE := '',\r\n",
      "    VERSION := '1.0']\r\n",
      "/array_1d (Array(10,)) 'A one-dimensional Array'\r\n",
      "  atom := Int8Atom(shape=(), dflt=0)\r\n",
      "  maindim := 0\r\n",
      "  flavor := 'numpy'\r\n",
      "  byteorder := 'irrelevant'\r\n",
      "  chunkshape := None\r\n",
      "  /array_1d._v_attrs (AttributeSet), 5 attributes:\r\n",
      "   [CLASS := 'ARRAY',\r\n",
      "    FLAVOR := 'numpy',\r\n",
      "    SomeAttribute := 'SomeValue',\r\n",
      "    TITLE := 'A one-dimensional Array',\r\n",
      "    VERSION := '2.4']\r\n",
      "/multidimensional_data (Group) 'Multi dimensional data'\r\n",
      "  /multidimensional_data._v_attrs (AttributeSet), 4 attributes:\r\n",
      "   [CLASS := 'GROUP',\r\n",
      "    SomeOtherAttribute := 123,\r\n",
      "    TITLE := 'Multi dimensional data',\r\n",
      "    VERSION := '1.0']\r\n",
      "/multidimensional_data/array_2d (Array(10, 3)) 'A two-dimensional Array'\r\n",
      "  atom := Float32Atom(shape=(), dflt=0.0)\r\n",
      "  maindim := 0\r\n",
      "  flavor := 'numpy'\r\n",
      "  byteorder := 'little'\r\n",
      "  chunkshape := None\r\n",
      "  /multidimensional_data/array_2d._v_attrs (AttributeSet), 4 attributes:\r\n",
      "   [CLASS := 'ARRAY',\r\n",
      "    FLAVOR := 'numpy',\r\n",
      "    TITLE := 'A two-dimensional Array',\r\n",
      "    VERSION := '2.4']\r\n",
      "/multidimensional_data/array_3d (Array(10, 3, 5)) 'A three-dimensional Array'\r\n",
      "  atom := Float32Atom(shape=(), dflt=0.0)\r\n",
      "  maindim := 0\r\n",
      "  flavor := 'numpy'\r\n",
      "  byteorder := 'little'\r\n",
      "  chunkshape := None\r\n",
      "  /multidimensional_data/array_3d._v_attrs (AttributeSet), 4 attributes:\r\n",
      "   [CLASS := 'ARRAY',\r\n",
      "    FLAVOR := 'numpy',\r\n",
      "    TITLE := 'A three-dimensional Array',\r\n",
      "    VERSION := '2.4']\r\n"
     ]
    }
   ],
   "source": [
    "# -a show attributes, -v verbose\n",
    "!ptdump -av 'data/my_pytables_file.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "/ (RootGroup)\r\n",
      "+--multidimensional_data (Group)\r\n",
      "|  +--array_3d (Array)\r\n",
      "|  |     mem=600.0B, disk=600.0B [82.2%]\r\n",
      "|  `--array_2d (Array)\r\n",
      "|        mem=120.0B, disk=120.0B [16.4%]\r\n",
      "`--array_1d (Array)\r\n",
      "      mem=10.0B, disk=10.0B [ 1.4%]\r\n",
      "\r\n",
      "------------------------------------------------------------\r\n",
      "Total branch leaves:    3\r\n",
      "Total branch size:      730.0B in memory, 730.0B on disk\r\n",
      "Mean compression ratio: 1.00\r\n",
      "HDF5 file size:         6.0kB\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pttree -L 2 --use-si-units --sort-by 'size' 'data/my_pytables_file.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 Viewers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [HDFView](https://support.hdfgroup.org/products/java/hdfview/): I like it!\n",
    "- [HDF Compass](https://support.hdfgroup.org/projects/compass/): seems to be the go-to choice for Mac users\n",
    "- [ViTables](http://vitables.org/): weird... indexing starts at 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Remember when I said \"let's forget HDF5 datasets for a moment\"?\n",
    "\n",
    "> Here is why..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PyTables provides high-level abstractions over the HDF5 Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Homogenous dataset:\n",
    "\n",
    "- **Array**\n",
    "- **CArray**\n",
    "- **EArray**\n",
    "- **VLArray**\n",
    "\n",
    "Heterogenous dataset:\n",
    "\n",
    "- **Table**\n",
    "\n",
    "*Note*: some HDF5 libraries/tools could create a HDF5 dataset currently not supported by PyTables. In this case the dataset will be mapped into an [UnImplemented](http://www.pytables.org/usersguide/libref/helper_classes.html#tables.UnImplemented) class instance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wait! What is a *Homogeneous* dataset?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A homogeneous dataset is a dataset where all its elements have the same [Atom](http://www.pytables.org/usersguide/libref/declarative_classes.html#atomclassdescr).\n",
    "\n",
    "An Atom represents the **type and shape** of the atomic objects to be saved.\n",
    "\n",
    "It's the most basic, indivisible element that can be stored in a given dataset. Atoms have the property that their length is always the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Atom(shape=(2,), dflt=0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "atom = tb.Int64Atom(shape=(2,))\n",
    "atom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docs](http://www.pytables.org/usersguide/libref/homogenous_storage.html#the-array-class)\n",
    "\n",
    "An Array contains homogeneous data. Every atomic object (i.e. every single element) has the same type and shape.\n",
    "\n",
    "- Fastest I/O speed\n",
    "- Must fit in memory\n",
    "- Not compressible\n",
    "- Not enlargeable (i.e. no append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    f.create_array(where='/', \n",
    "                   name='array_1d',\n",
    "                   title='A one-dimensional Array',\n",
    "                   obj=[0, 1, 2, 3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docs](http://www.pytables.org/usersguide/libref/homogenous_storage.html#carrayclassdescr)\n",
    "\n",
    "- Chunked layout, compressible\n",
    "- Not enlargeable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = tb.Filters(complevel=5, complib='zlib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tips on how to use compression (from the PyTables docs)\n",
    "\n",
    "- A mid-level (5) compression is sufficient. No need to go all the way up (9)\n",
    "- Use zlib if you must guarantee complete portability\n",
    "- Use blosc all other times (it is optimized for HDF5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    f.create_carray(\n",
    "        where='/',\n",
    "        name='my_carray',\n",
    "        title='My PyTables CArray',\n",
    "        obj=arr2d,\n",
    "        filters=filters)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docs](http://www.pytables.org/usersguide/libref/homogenous_storage.html#earrayclassdescr)\n",
    "\n",
    "- Enlargeable on **one** dimension (append)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One (and only one) of the shape dimensions *must* be 0.\n",
    "# The dimension being 0 means that the resulting EArray object can be extended along it.\n",
    "# Multiple enlargeable dimensions are not supported (at the moment).\n",
    "num_columns = 5\n",
    "shape = (0, num_columns)\n",
    "\n",
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    # you can create an EArray and fill it later, but you need to specify atom and shape\n",
    "    f.create_earray(\n",
    "        where='/',\n",
    "        name='my_earray',\n",
    "        title='My PyTables EArray',\n",
    "        atom=tb.Float32Atom(),\n",
    "        shape=shape,\n",
    "        filters=filters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_rows = 1000000  # 1 million\n",
    "matrix = np.random.random((num_rows, num_columns)).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='a') as f:\n",
    "    earray = f.root.my_earray\n",
    "    earray.append(sequence=matrix[0:1000, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='a') as f:\n",
    "    earray = f.root.my_earray\n",
    "    earray.append(sequence=matrix[1001:5000, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VLArray"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docs](http://www.pytables.org/usersguide/libref/homogenous_storage.html#the-vlarray-class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each row has a variable number of homogeneous elements (atoms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    vlarray = f.create_vlarray(where='/',\n",
    "                               name='my_vlarray',\n",
    "                               atom=atom,\n",
    "                               title='Variable length array of vectors')\n",
    "    vlarray.append([[0, 1]])\n",
    "    vlarray.append([[2, 3], [4, 5], [6, 7]])\n",
    "    vlarray.append([[8, 9]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Docs](http://www.pytables.org/usersguide/libref/structured_storage.html?highlight=table#tableclassdescr)\n",
    "\n",
    "- Data can be heterogeneous (i.e. different shapes and different dtypes)\n",
    "- The structure of a table is declared by its [description](http://www.pytables.org/usersguide/libref/declarative_classes.html#tables.IsDescription)\n",
    "- multi-column searches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to emulate in Python records mapped to HDF5 C structs PyTables implements a special class so as to easily define all its fields and other properties. It's called `IsDescription`.\n",
    "\n",
    "A *description* defines the table structure (basically, the *schema* of your table)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Example: NYC yellow taxi dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Taxi & Limousine Commission Trip Record Data](http://www.nyc.gov/html/tlc/html/about/trip_record_data.shtml)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"LocationID\",\"Borough\",\"Zone\",\"service_zone\"\n",
      "1,\"EWR\",\"Newark Airport\",\"EWR\"\n",
      "2,\"Queens\",\"Jamaica Bay\",\"Boro Zone\"\n",
      "3,\"Bronx\",\"Allerton/Pelham Gardens\",\"Boro Zone\"\n",
      "4,\"Manhattan\",\"Alphabet City\",\"Yellow Zone\"\n",
      "5,\"Staten Island\",\"Arden Heights\",\"Boro Zone\"\n",
      "6,\"Staten Island\",\"Arrochar/Fort Wadsworth\",\"Boro Zone\"\n",
      "7,\"Queens\",\"Astoria\",\"Boro Zone\"\n",
      "8,\"Queens\",\"Astoria Park\",\"Boro Zone\"\n",
      "9,\"Queens\",\"Auburndale\",\"Boro Zone\"\n",
      "10,\"Queens\",\"Baisley Park\",\"Boro Zone\"\n",
      "11,\"Brooklyn\",\"Bath Beach\",\"Boro Zone\"\n",
      "12,\"Manhattan\",\"Battery Park\",\"Yellow Zone\"\n",
      "13,\"Manhattan\",\"Battery Park City\",\"Yellow Zone\"\n",
      "14,\"Brooklyn\",\"Bay Ridge\",\"Boro Zone\"\n",
      "15,\"Queens\",\"Bay Terrace/Fort Totten\",\"Boro Zone\"\n",
      "16,\"Queens\",\"Bayside\",\"Boro Zone\"\n",
      "17,\"Brooklyn\",\"Bedford\",\"Boro Zone\"\n",
      "18,\"Bronx\",\"Bedford Park\",\"Boro Zone\"\n",
      "19,\"Queens\",\"Bellerose\",\"Boro Zone\"\n",
      "20,\"Bronx\",\"Belmont\",\"Boro Zone\"\n",
      "21,\"Brooklyn\",\"Bensonhurst East\",\"Boro Zone\"\n",
      "22,\"Brooklyn\",\"Bensonhurst West\",\"Boro Zone\"\n",
      "\u001b[K:\u001b[Ka/taxi+_zone_lookup.csv\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!less 'data/taxi+_zone_lookup.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VendorID,tpep_pickup_datetime,tpep_dropoff_datetime,passenger_count,trip_distance,RatecodeID,store_and_fwd_flag,PULocationID,DOLocationID,payment_type,fare_amount,extra,mta_tax,tip_amount,tolls_amount,improvement_surcharge,total_amount\n",
      "\n",
      "1,2017-12-01 00:12:00,2017-12-01 00:12:51,1,.00,1,N,226,226,3,2.5,0.5,0.5,0,0,0.3,3.8\n",
      "1,2017-12-01 00:13:37,2017-12-01 00:13:47,1,.00,1,N,226,226,3,2.5,0.5,0.5,0,0,0.3,3.8\n",
      "1,2017-12-01 00:14:15,2017-12-01 00:15:05,1,.00,1,N,226,226,3,2.5,0.5,0.5,0,0,0.3,3.8\n",
      "1,2017-12-01 00:15:33,2017-12-01 00:15:37,1,.00,1,N,226,226,3,2.5,0.5,0.5,0,0,0.3,3.8\n",
      "1,2017-12-01 00:50:03,2017-12-01 00:53:35,1,.00,1,N,145,145,2,4,0.5,0.5,0,0,0.3,5.3\n",
      "1,2017-12-01 00:14:20,2017-12-01 00:28:35,1,4.20,1,N,82,258,2,15,0.5,0.5,0,0,0.3,16.3\n",
      "1,2017-12-01 00:20:32,2017-12-01 00:31:24,1,5.40,1,N,50,116,2,17,0.5,0.5,0,0,0.3,18.3\n",
      "1,2017-12-01 00:01:46,2017-12-01 00:12:19,1,1.90,1,N,161,107,1,9,0.5,0.5,2.05,0,0.3,12.35\n",
      "1,2017-12-01 00:17:52,2017-12-01 00:32:35,1,3.30,1,N,107,263,1,12.5,0.5,0.5,2.07,0,0.3,15.87\n",
      "\u001b[K:\u001b[K12-01 00:10:00,2017-12-01 00:24:35,1,2.80,1,N,264,87,1,12,0.5,0.5,2.65,0,\u001b[7mdata/yellow_tripdata_2017-12.csv\u001b[m\u001b[K\u0007"
     ]
    }
   ],
   "source": [
    "!less 'data/yellow_tripdata_2017-12.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a description object to pass to the `Table` constructor. The information it contains will be used to define the table structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TaxiTableDescription(tb.IsDescription):\n",
    "    vendor_id = tb.UInt8Col(pos=0)\n",
    "    pickup_timestamp_ms = tb.Int64Col()\n",
    "    dropoff_timestamp_ms = tb.Int64Col()\n",
    "    passenger_count = tb.UInt8Col()\n",
    "    trip_distance = tb.Float32Col()\n",
    "    pickup_location_id = tb.UInt16Col()\n",
    "    dropoff_location_id = tb.UInt16Col()\n",
    "    payment_type = tb.UInt8Col()\n",
    "    fare_amount = tb.Float32Col()\n",
    "    tip_amount = tb.Float32Col()\n",
    "    total_amount = tb.Float32Col()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "HDF5 is *self-describing*: you can store the data dictionary as metadata. No need for external files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data dictionary for NY yellow taxi CSV files\n",
    "# http://www.nyc.gov/html/tlc/downloads/pdf/data_dictionary_trip_records_yellow.pdf\n",
    "data_dictionary = {\n",
    "    'VendorID': 'A code indicating the TPEP provider that provided the record',\n",
    "    'tpep_pickup_datetime': 'The date and time when the meter was engaged ',\n",
    "    'tpep_dropoff_datetime': 'The date and time when the meter was disengaged ',\n",
    "    'passenger_count': 'The number of passengers in the vehicle',\n",
    "    'trip_distance': 'The elapsed trip distance in miles reported by the taximeter',\n",
    "    'PULocationID': 'A code indicating the zone + borough of th pickup location',\n",
    "    'DOLocationID': 'A code indicating the zone + borough of th dropoff location',\n",
    "    'payment_type': 'A numeric code signifying how the passenger paid for the trip',\n",
    "    'fare_amount': 'The time-and-distance fare calculated by the meter',\n",
    "    'tip_amount': 'Tip amount â€“ This field is automatically populated for credit card tips. Cash tips are not included',\n",
    "    'total_amount': 'The total amount charged to passengers. Does not include cash tips',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jack/Repos/hdf5-pycon-slovakia/data/NYC-yellow-taxis-100k.h5\n"
     ]
    }
   ],
   "source": [
    "h5_file_path = os.path.join(data_dir, 'NYC-yellow-taxis-100k.h5')\n",
    "print(h5_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = tb.Filters(complevel=5, complib='zlib')\n",
    "\n",
    "with tb.open_file(filename=h5_file_path, mode='w') as f:\n",
    "    # create table with pre-defined schema\n",
    "    f.create_table(\n",
    "        where='/',\n",
    "        name='yellow_taxis_2017_12',\n",
    "        description=TaxiTableDescription,\n",
    "        title='NYC Yellow Taxi data December 2017',\n",
    "        filters=filters)\n",
    "    # add metadata\n",
    "    table_where = '/yellow_taxis_2017_12'\n",
    "    for key, val in data_dictionary.items():\n",
    "        f.set_node_attr(where=table_where, attrname=key, attrvalue=val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/ (RootGroup) ''\n",
      "/yellow_taxis_2017_12 (Table(0,), shuffle, zlib(5)) 'NYC Yellow Taxi data December 2017'\n"
     ]
    }
   ],
   "source": [
    "!ptdump 'data/NYC-yellow-taxis-100k.h5'  # try also h5dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_to_timestamp_ms(date_obj):\n",
    "    timestamp_in_nanoseconds = date_obj.astype('int64')\n",
    "    timestamp_in_ms = (timestamp_in_nanoseconds / 1000000).astype('int64')\n",
    "    return timestamp_in_ms\n",
    "\n",
    "def fill_table(table, mapping, df):\n",
    "    num_records = df.shape[0]  # it's equal to the chunksize used in read_csv\n",
    "    row = table.row\n",
    "    for i in range(num_records):\n",
    "        row['vendor_id'] = df[mapping['vendor_id']].values[i]\n",
    "\n",
    "        pickup_ms = date_to_timestamp_ms(df[mapping['pickup_datetime']].values[i])\n",
    "        row['pickup_timestamp_ms'] = pickup_ms\n",
    "        dropoff_ms = date_to_timestamp_ms(df[mapping['dropoff_datetime']].values[i])\n",
    "        row['dropoff_timestamp_ms'] = dropoff_ms\n",
    "\n",
    "        row['passenger_count'] = df['passenger_count'].values[i]\n",
    "        row['trip_distance'] = df['trip_distance'].values[i]\n",
    "\n",
    "        row['pickup_location_id'] = df['PULocationID'].values[i]\n",
    "        row['dropoff_location_id'] = df['DOLocationID'].values[i]\n",
    "\n",
    "        row['fare_amount'] = df['fare_amount'].values[i]\n",
    "        row['tip_amount'] = df['tip_amount'].values[i]\n",
    "        row['total_amount'] = df['total_amount'].values[i]\n",
    "\n",
    "        row['payment_type'] = df['payment_type'].values[i]\n",
    "        row.append()\n",
    "    table.flush()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remember to flush:* Remember, flushing a table is a very important step as it will not only help to maintain the integrity of your file, but also will free valuable memory resources (i.e. internal buffers) that your program may need for other things."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.1 s, sys: 0 ns, total: 10.1 s\n",
      "Wall time: 10.5 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Open the HDF5 file in 'a'ppend mode and populate the table with CSV data\n",
    "with tb.open_file(filename=h5_file_path, mode='a') as f:\n",
    "    # Left, the key we want to use. Right, the key in the CSV file\n",
    "    mapping = {\n",
    "        'vendor_id': 'VendorID',\n",
    "        'pickup_datetime': 'tpep_pickup_datetime',\n",
    "        'dropoff_datetime': 'tpep_dropoff_datetime',\n",
    "        'pickup_location_id': 'PULocationID',\n",
    "        'dropoff_location_id': 'DOLocationID'\n",
    "    }\n",
    "\n",
    "    # define the dtype to use when reading the CSV with pandas (this has nothing to do with the HDF5 table)\n",
    "    dtype = {'VendorID': 'category', 'payment_type': 'category'}\n",
    "    parse_dates = ['tpep_pickup_datetime', 'tpep_dropoff_datetime']\n",
    "\n",
    "    table = f.get_node(where='/yellow_taxis_2017_12')\n",
    " \n",
    "    csv_file_path = os.path.join(data_dir, 'yellow_tripdata_2017-12.csv')\n",
    "\n",
    "    # read in chunks because these CSV files are too big\n",
    "    chunksize = 100000\n",
    "    for chunk in pd.read_csv(\n",
    "        csv_file_path, chunksize=chunksize, dtype=dtype,\n",
    "        skipinitialspace=True, parse_dates=parse_dates):\n",
    "        df = chunk.reset_index(drop=True)\n",
    "        fill_table(table, mapping, df)\n",
    "        # remove the break statement to process all chunks (it will take ~20 minutes)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n",
      "/ (RootGroup)\r\n",
      "`--yellow_taxis_2017_12 (Table)\r\n",
      "      mem=3.9MB, disk=1.8MB [100.0%]\r\n",
      "\r\n",
      "------------------------------------------------------------\r\n",
      "Total branch leaves:    1\r\n",
      "Total branch size:      3.9MB in memory, 1.8MB on disk\r\n",
      "Mean compression ratio: 0.45\r\n",
      "HDF5 file size:         1.8MB\r\n",
      "------------------------------------------------------------\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "!pttree --use-si-units --sort-by 'size' 'data/NYC-yellow-taxis-100k.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Expressions with NumExpr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[NumExpr](https://github.com/pydata/numexpr) is an expression evaluator for NumPy.\n",
    "\n",
    "- Parses expressions into its own bytecode that is then used by an integrated computing virtual machine written in C\n",
    "- Processes chunks of elements at a time.\n",
    "- The compilation step has some overhead, so NumExpr achieves better speedups with large arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_elements = 1000000  # 1 million\n",
    "x = np.random.uniform(low=1, high=5, size=num_elements).astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 120 ms, sys: 16 ms, total: 136 ms\n",
      "Wall time: 132 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    carray = f.create_carray(where='/', name='carray_without_numexpr', atom=tb.Float32Atom(), shape=x.shape)\n",
    "    carray[:] = x**3 + 0.5*x**2 - x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28 ms, sys: 24 ms, total: 52 ms\n",
      "Wall time: 42.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    carray = f.create_carray(where='/', name='carray_with_numexpr', atom=tb.Float32Atom(), shape=x.shape)\n",
    "    ex = tb.Expr('x**3 + 0.5*x**2 - x')\n",
    "    ex.set_output(carray) # output will got to the CArray on disk\n",
    "    ex.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Searches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74411\n",
      "CPU times: user 528 ms, sys: 0 ns, total: 528 ms\n",
      "Wall time: 527 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "with tb.open_file(filename='data/NYC-yellow-taxis-100k.h5', mode='r') as f:\n",
    "    table = f.get_node(where='/yellow_taxis_2017_12')\n",
    "    rows = table.read()\n",
    "    amounts = [row['total_amount'] for row in rows if row['passenger_count'] == 1]\n",
    "    \n",
    "print(len(amounts))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create custom datatype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/tomkooij/scipy2017/blob/master/notebooks/02-Datatypes-in-HDF5.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Links"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "external links, soft links, hard links.\n",
    "\n",
    "See https://github.com/PyTables/PyTables/blob/develop/examples/links.py\n",
    "\n",
    "See http://www.pytables.org/usersguide/libref/file_class.html#tables.File.create_external_link"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add column to table (like a database schema migration)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filenode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/PyTables/PyTables/blob/develop/examples/filenodes1.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### todo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transactions: mark, undo, redo, goto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See https://github.com/PyTables/PyTables/blob/develop/examples/undo-redo.py\n",
    "\n",
    "See https://github.com/PyTables/PyTables/blob/develop/examples/tutorial3-2.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This operation prepares the database for undoing and redoing modifications in the node hierarchy.\n",
    "\n",
    "Once the Undo/Redo mechanism is enabled, explicit marks (with an optional unique name) can be set on the state of the database using the File.mark() method. There are two implicit marks which are always available: the initial mark (0) and the final mark (-1).\n",
    "\n",
    "I personally find the method name `undo` a bit misleading and inconsistent (`undo` without specifying a mark rollback last transaction, with a mark with `'after b'` it return to the state marked as `'after b'`).\n",
    "\n",
    "File.undo() method, which returns the database to the state of a past mark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "with tb.open_file(filename='data/my_pytables_file.h5', mode='w') as f:\n",
    "    f.enable_undo()\n",
    "    \n",
    "    f.create_array(where='/', name='array_a', title='Array A', obj=[1, 2, 3])\n",
    "    f.mark(name='after a')\n",
    "    \n",
    "    f.create_array(where='/', name='array_b', title='Array B', obj=[4, 5, 6])\n",
    "    f.mark(name='after b')\n",
    "    \n",
    "    f.create_array(where='/', name='array_c', title='Array C', obj=[7, 8, 9])\n",
    "    f.mark(name='after c')\n",
    "    \n",
    "#     f.undo(mark='after b')\n",
    "#     f.redo(mark='after c')\n",
    "    f.goto(mark='after a')\n",
    "#     f.disable_undo()\n",
    "    current_mark = f.get_current_mark()\n",
    "    print(current_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You cannot undo/redo everything! EXAMPLES?\n",
    "\n",
    "Hierarchy manipulation operations on nodes that do not support the Undo/Redo mechanism issue an UndoRedoWarning before changing the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(current_mark)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HDF5 users, use cases and job offers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add special thanks to all those replied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [Introduction to HDF5](https://www.youtube.com/watch?v=BAjsCldRMMc) by Quincey Koziol\n",
    "- [HDF5 take 2 - h5py & PyTables](https://www.youtube.com/watch?v=ofLFhQ9yxCw) by Tom Kooij\n",
    "- [PyTables documentation](http://www.pytables.org/usersguide/index.html)\n",
    "- [The starving CPU problem](https://python.g-node.org/python-summerschool-2013/_media/starving_cpu/starvingcpus.pdf) by Francesc Alted"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Special thanks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "[Julien Guillaumin](https://www.linkedin.com/in/julienguillaumin): HDF5 image augmentation for deep learning applications"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
